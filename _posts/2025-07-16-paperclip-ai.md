---
layout: post
title: Billionaires are already producing paperclips
excerpt: AI companies are destroying the environment while trying to have us believe they are saving us.
tags: [ethics, ai]
---

# Billionaires are already producing paperclips
{:.no_toc}

Published: {{page.date | date_to_long_string: "ordinal"}}
{: .date}

There’s this [game](https://en.wikipedia.org/wiki/Universal_Paperclips) which I remember playing a few years back. The goal is to make paperclips, and not stop at anything to do that. It’s inspired by a thought experiment by Nick Bostrom about an AI which could destroy humanity because it was programmed to just keep on making paperclips. Back in the day, I thought it was a nice thought experiment. Now, I’m not too sure it really brings across the message Bostrom wanted: that we should fear AI because it might at one point lead to extinction.

The idea is frightening: an entity which destroys our environment because it tries to fulfil a sole, narrow purpose. But while an AI producing paperclips still seems a little farfetched, I think it’s not hard to see a parallel with exactly the companies who are saying they do research into AI to prevent extinction by it. 

Companies like OpenAI who are burning through money to build enormous data centers, for which apparently [‘new energy sources’ are needed](https://fortune.com/2024/09/27/openai-5gw-data-centers-altman-power-requirements-nuclear/) and for now [more fossil fuel is burned](https://time.com/6987773/ai-data-centers-energy-usage-climate-change/). And of course it requires the mining of an enormous amount of metals, which happens under horrible circumstances and destroys our earth even more. 

So for the aim of pleasing investors, making the company worth more (i.e. the sole, narrow purpose of making the number go up) these AI companies and their billionaire owners are doing exactly what they [pretend to prevent](https://openai.com/charter/): enormous amounts of human suffering (through destroying our environment).

Now, it doesn’t come as a surprise to me that Bostrom didn’t warn about harm to actual people living now, and instead talked about vague and potential future harm. This fits neatly with the [TESCREAList movement](https://www.truthdig.com/articles/the-acronym-behind-our-wildest-ai-dreams-and-nightmares/) he is a part of. Still, I thought this was a neat illustration of the problems with longtermism and the charitable facade OpenAI put(s) on.